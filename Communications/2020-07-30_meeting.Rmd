---
title: "Translation Elicitation"
date: "30/07/2020"
output: html_document
---

```{r prepare, include=FALSE}

library(dplyr)
library(papaja)
library(tidyr)
library(tibble)
library(janitor)
library(stringr)
library(forcats)
library(ggplot2)
library(patchwork)
library(here)
library(data.table)
library(broom)
library(brms)
library(effectsize)
library(pairwiseComparisons)
library(tidybayes)
library(gt)
library(lubridate)

participants <- fread(here("Data", "02_participants.csv"), na.strings = c("", "NA")) %>%
  as_tibble() %>%
  mutate(date = as_date(date),
         group = as.factor(group))
contrasts(participants$group) <-  contr.helmert(3)/2

trials <- fread(here("Data", "trial_stats.csv"),
                na.strings = c("", "NA")) %>%
  as_tibble() %>%
  clean_names()

accuracy <- fread(here("Data", "03_accuracy_coded.csv"),
                  na.strings = c("", "NA")) %>%
  as_tibble() %>% 
  mutate(correct_coded = response_type %in% c("correct", "typo"),
         correct_coded = as.numeric(correct_coded))

posterior <- fread(here("Results", "posterior_draws.csv"),
                   na.strings = c("", "NA")) %>%
  as_tibble()

prior <- fread(here("Results", "prior_draws.csv"),
               na.strings = c("", "NA")) %>%
  as_tibble()

predictions <- fread(here("Results", "posterior_predictions.csv"),
                     na.strings = c("", "NA")) %>%
  as_tibble()

fit <- readRDS(here("Results", "fit4_phon.rds"))
loos <- readRDS(here("Results", "loos.rds"))
r2 <- readRDS(here("Results", "r2.rds"))

item_effects <- fread(here("Results", "item_effects.csv"),
                      na.strings = c("", "NA")) %>%
  as_tibble()

group_effects <- fread(here("Results", "group_effects.csv"),
                       na.strings = c("", "NA")) %>%
  as_tibble()

corrs <- fread(here("Results", "corrs.csv"),
               na.strings = c("", "NA")) %>%
  as_tibble()

valid_participant <- filter(participants, valid_participant) %>% pull(participant)

clean_varnames <- function(x){
  str_remove({{ x }}, "b_") %>% 
    str_replace_all(., "pthn", "PTHN") %>% 
    str_replace_all(., "similarity_phon", "Phon. Similarity") %>% 
    str_replace_all(., ":", " \U000D7 ")
}

```

# Behavioural task

## Sample

`r nrow(participants)` participants (mean age = `r printnum(mean(participants$age, na.rm = TRUE))`, *SD* age = `r printnum(sd(participants$age, na.rm = TRUE))`, age range = `r printnum(min(participants$age, na.rm = TRUE))`-`r printnum(max(participants$age, na.rm = TRUE))`). 

`r filter(participants, country=="UK") %>% nrow()` participants were British English native speakers living in United Kingdom (`r filter(participants, country=="UK", sex =="Female") %>% nrow()` female), and `r filter(participants, country=="Spain") %>% nrow()` participants were Spanish native speakers living in Spain (`r filter(participants, country=="Spain", sex =="Female") %>% nrow()` female). 


Exclusion criteria:

a) Oral and/or written skills in a second or third language as higher than 4 in a 5-point scale (*n* = `r filter(participants, l2oral>4 | l2written>4) %>% nrow()`)
b) Language impairment (*n* = `r filter(participants, impairment) %>% nrow()`)^[We originally planned to exclude participants that reported any visual impairment that glasses would not correct. This item was phrased as *Do you have normal or corrected-to-normal VISION? (Yes/No)* in English, and as *¿Tienes problemas de VISIÓN que unas gafas o lentes de contacto NO corrijan? (Sí/No)*. Surprisingly, the proportion of Spanish participants that reported visual impairment was implausibly large (*n* = `r nrow(filter(participants, country %in% "Spain", vision))`, `r printnum((1-nrow(filter(participants, country %in% "Spain", !vision))/nrow(filter(participants, country=="Spain")))*100)`%). This is possibly due to some participants using glasses daily and not having read the item until the end, where it is indicated that the use of glasses is considered as normal vision.]
c) Did not contribute more than 80% of valid trials (*n* = `r sum(participants$invalid_participant_trials, na.rm = TRUE)`)

This resulted in `r nrow(participants)-sum(participants$valid_participant)` participants excluded, leaving `r nrow(filter(participants, valid_participant))` valid participants and `r accuracy %>% filter(response_type %in% c("correct", "typo", "wrong", "false_friend")) %>% nrow() %>% printnum(big.mark = ",")` valid trials.


```{r participants_prof_l2, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.cap="Second languages. Some participants reported being familiar with one or more langugaes other than English (for UK participants) or Spanish (for participants in Spain). We asked them to self-report their oral and written proficiency in those languages in a 0-to-5 scale. This graph shows the mean proficiency reported by participants that reported being familiar with each language. the number of participants that reported being familiar with each language is reported on top of each bar. Data are presented for UK and Spanish participants separately."}

participants %>%
  filter(!(l2 %in% "None")) %>% 
  pivot_longer(c(l2oral, l2written), names_to = "modality", values_to = "proficiency") %>%
  mutate(modality = str_to_sentence(str_remove(modality, "l2"))) %>%
  group_by(l2, country, modality) %>% 
  summarise(mean = mean(proficiency, na.rm = TRUE),
            n = n(), .groups = "drop") %>%
  arrange(n) %>% 
  mutate(l2 = fct_inorder(as.factor(l2))) %>% 
  ggplot(aes(l2, mean, fill = l2)) +
  facet_wrap(country~modality) +
  geom_col(show.legend = FALSE) +
  geom_text(aes(y = mean-0.5, label = paste0("n = ", n)), size = 3) +
  labs(x = "L2", y = "Self-rated proficiency (0-5)") +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  scale_y_continuous(limits = c(0, 5)) +
  theme_classic() +
  theme(panel.grid.major.y = element_line(colour = "grey", linetype = "dotted"),
        axis.title.x = element_blank(),
        axis.text = element_text(colour = "black"))

```

```{r participants_prof_spacat, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.cap="We also asked participants to rate their oral and written proficiency in the target languages (Spanish and Catalan). UK participants were aked about Spanish and Catalan while Spanish participants were aonly asked about Catalan. The graph represents how many participants (self-) reported each levels of proficiency (0-5). Data are presented separately for UK and Spanish participants."}

participants %>%
  pivot_longer(c(spanish_oral, spanish_written, catalan_oral, catalan_written), names_to = "language", values_to = "proficiency") %>%
  separate(language, c("language", "modality"), sep = "_") %>% 
  mutate(modality = str_to_sentence(str_remove(modality, "l2")),
         language = as.factor(str_to_sentence(language))) %>% 
  group_by(language, country, modality, proficiency) %>% 
  summarise(n = n(), .groups = "drop") %>% 
  ggplot(aes(x = proficiency, y = n, fill = country)) +
  facet_wrap(language~modality) +
  geom_col() +
  labs(y = "Count", x = "Self rated proficiency (0-5)", fill = "Country") +
  scale_x_continuous(limits = c(0, 5)) +
  theme_classic() +
  theme(panel.grid.major.y = element_line(colour = "grey", linetype = "dotted"),
        axis.text = element_text(colour = "black"))

```

## Design

* 0 - 1000 ms: fixation point
* 1000 - 2500 ms: audio
* 2500 ms - Press RETURN key: type response


## Stimuli

```{r stimuli, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.cap="Distribution of trial words from the three groups accross different levels of the predictors."}

plot_onset <- trials %>%
  select(trial_id, word, language, matches("same_onset")) %>% 
  rename_all(str_remove, "same_") %>% 
  pivot_longer(matches("onset"), names_to = "language_pair", values_to = "onset") %>%  
  mutate(language_pair = str_to_upper(str_remove(language_pair, "onset_")),
         onset = ifelse(str_detect(onset, "same"), "Same", "Different")) %>% 
  drop_na(onset) %>% 
  ggplot(aes(onset, colour = language_pair, fill = language_pair)) +
  facet_wrap(~language_pair) +
  geom_bar(position = position_dodge(width = 1), na.rm = TRUE) +
  labs(x = "Onset", y = "Counts",
       colour = "Language pair", fill = "Language pair") +
  theme_classic() +
  theme(legend.position = "none") 

plot_subs <- trials %>%
  select(trial_id, word, language, matches("close_|similarity"), -matches("ort")) %>% 
  rename_all(str_remove, "close_") %>% 
  pivot_longer(matches("substitutions|similarity"), names_to = c("measure", "language_pair"), values_to = "value", names_sep = "_") %>% 
  pivot_wider(names_from = "measure", values_from = "value") %>% 
  mutate(language_pair = str_to_upper(str_remove(language_pair, "substitutions_"))) %>% 
  ggplot(aes(similarity, substitutions, colour = language_pair, fill = language_pair)) +
  geom_point(alpha = 0.5, shape = 1) +
  geom_smooth(formula = "y ~ x", method = "lm") +
  labs(x = "Close substitutions", y = "Base similarity",
       colour = "Language pair", fill = "Language pair") +
  scale_y_continuous(limits = c(0, 1)) +
  theme_classic() +
  theme(legend.position = "none")
  
  
plot_sim <- trials %>%
  select(trial_id, word, language, matches("similarity")) %>% 
  rename_all(str_remove, "similarity_") %>% 
  rename_at(vars(4:9), ~paste0("phon_", .)) %>% 
  rename_at(vars(4:9), str_replace, "phon_ort_", "ort_") %>% 
  pivot_longer(4:9, names_to = c("modality", "language_pair"), values_to = "similarity", names_sep = "_") %>% 
  pivot_wider(names_from = modality, values_from = similarity) %>% 
  mutate(language_pair = str_to_upper(language_pair)) %>% 
  ggplot(aes(ort, phon, colour = language_pair, fill = language_pair)) +
  geom_point(alpha = 0.5, shape = 1) +
  geom_smooth(formula = "y ~ x", method = "lm") +
  labs(x = "Orthographical similarity", y = "Base similarity",
       colour = "Language pair", fill = "Language pair") +
  scale_y_continuous(limits = c(0, 1)) +
  scale_x_continuous(limits = c(0, 1)) +
  theme_classic() 
  
plot_onset + plot_subs + plot_sim + guide_area() +
  plot_layout(nrow = 2, guides = "collect") &
  theme(axis.text = element_text(colour = "black"),
        panel.grid.major.y = element_line(colour = "grey", linetype = "dotted"))

```



## Data analysis

We fit Bayesian logistic models to model the probability of participants typing a correct translation in each trial. As predictors, we included:

* *PTHN*: the number of more frequent phonological neighbours of the translation (`PTHN`, standardised)
* *Onset*: do both translation equivalents start with the same phoneme? (`same_onset`, with levels `Different`, and `Same`, sum-coded as `different` (-0.5) vs. `same` (0.5)
* *Close substitutions*: proportion of phoneme matches differing by 1 level on 1 feature (`close_substitutions`, standardised).
* *Base similarity*: Proportion of phoneme matches with identical codes (`similarity_phon`, standardised).

We first for a null model `fit1_pthn` that only included PTHN as predictor. We then extended the model by fitting three other models that included one of the predictors of interest (*Onset*, *Close substitutions*, or *Base similarity*) in interaction with *PTHN*. Finally, we fitted a model that included the traditional orthographical Levenshtein similarity (`similarity_ort`, standardised) to test whether our phonology-based measure predicted participants responses better than just relying on orthography. The models included a maximal random-effects structure (with random intercepts and slopes for all fixed effects) and were implemented in the `brms` R package using the following formulas:

* `fit1_pthn <- correct | trials(total) ~ pthn + (1 + pthn | group)`
* `fit2_onset <- correct | trials(total) ~ pthn*same_onset + (1 +  pthn*same_onset | group)`
* `fit3_close <- correct | trials(total) ~ pthn*close_substitutions + (1 + pthn*close_substitutions | group)`
* `fit4_phon <- correct | trials(total) ~ pthn*similarity_phon + (1 + pthn*similarity_phon | group)`
* `fit5_ort <- correct | trials(total) ~ pthn*similarity_ort + (1 + pthn*similarity_ort | group)`



# Results


```{r accuracy_anova, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}

model <- lm(prop_correct ~ group, data = participants)
anov <- anova(model) %>% 
  tidy()

es <- anov$sumsq[1]/(anov$sumsq[1]+anov$sumsq[2])
pairs <- pairwise_comparisons(data = participants,
                              x = group,
                              y = prop_correct, type = "parametric",
                              p.adjust.method = "bonferroni") %>% 
  select(-c(label, test.details, p.value.adjustment, significance))


```

We performed a one-way ANOVA to analyse how participants' accuracy (the proportion of correct trials) changed across groups the three groups (ENG-SPA, ENG-CAT, and SPA-CAT). The `group` predictor explained a significant proportion of the variance, *F*(`r printnum(anov$df[1])`, `r printnum(anov$df[2])`) = `r printnum(anov$statistic[1])`, `r printp(anov$p.value[1])`, $\hat{\eta}^2$ = `r printnum(es)`). Follow-up *t*-tests revealed that Spanish-native speakers translating Catalan words (ENG-SPA, ENG-CAT), *t*(`r printnum(pairs$df[3])`) = `r printnum(pairs$t.value[3])`, `r printp(pairs$p.value[3])`, Cohen's *d* = `r printnum(pairs$t.value[3]/sqrt(nrow(filter(participants, group %in% c("SPA-CAT", "ENG-SPA")))))`), or Catalan words, *t*(`r printnum(pairs$df[2])`) = `r printnum(pairs$t.value[2])`, `r printp(pairs$p.value[2])`, Cohen's *d* = `r printnum(pairs$t.value[2]/sqrt(nrow(filter(participants, group %in% c("SPA-CAT", "ENG-SPA")))))`). We did not find evidence against accuracy being similar in both English-native groups, , *t*(`r printnum(pairs$df[1])`) = `r printnum(pairs$t.value[1])`, `r printp(pairs$p.value[1])`, Cohen's *d* = `r printnum(pairs$t.value[1]/sqrt(nrow(filter(participants, group %in% c("SPA-CAT", "ENG-SPA")))))`). Bonferroni corrections were applied in the aforementioned contrasts.



```{r accuracy, echo=FALSE, fig.cap="Participants' overall accuracy across groups. The X-axis represents the native language of participants (English or Spanish) and the language participants listened during the task (Spanish or Catalan). The Y-axis represents the proportion of correct. Each datapoint corresponds to one participant. Horizontal black lines represent group means."}

ggplot(participants, aes(group, prop_correct, fill = group)) +
  geom_violin(colour = NA) +
  geom_boxplot(fill = "white", width = 0.1) +
  labs(x = "Group", y = "Accuracy (% correct trials)", fill = "Group") +
  scale_y_continuous(limits = c(0, 1)) +
  theme_classic() +
  theme(panel.grid.major.y = element_line(colour = "grey", linetype = "dotted"),
        legend.position = "none",
        axis.title.x = element_blank(),
        axis.text = element_text(colour = "black"))
```

## Model comparison


```{r comparison, echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE}
 
r2_table <- r2 %>%
  mutate(r2_ci95 = paste0("[", round(q2_5, 2), ", ", round(q97_5, 2), "]")) %>% 
  rename(r2 = estimate, r2_se = est_error) %>% 
  select(model, r2, r2_se, r2_ci95)
loos$diffs %>% 
  as.data.frame() %>% 
  rownames_to_column("model") %>% 
  select(model, elpd_diff, se_diff, elpd_loo, se_elpd_loo) %>% 
  left_join(r2_table) %>% 
  relocate(model, r2, r2_se, r2_ci95) %>% 
  gt() %>% 
  fmt_number(c(2, 3, 5, 6, 7, 8)) %>% 
  cols_label(model = "Model", r2 = "R2", r2_se = "SE", r2_ci95 = "95% CrI", elpd_diff = "\U0394 ELPD", se_diff = "\U0394 SE", elpd_loo = "ELPD LOO", se_elpd_loo = "SE ELPD LOO") %>%
  tab_spanner(label = "R2", columns = matches("r2")) %>% 
  tab_spanner(label = "PSIS-LOO", columns = matches("loo|diff"))



```


## Posterior distributions

```{r posterior_coefs, echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE, fig.cap="Point estimations (median), standard errors, 95% credible intervals, and diagnostics of the fixed efffects of the model."}

summary(fit)$fixed %>%
  as.data.frame() %>% 
  rownames_to_column("term") %>% 
  clean_names() %>% 
  mutate(ci95 = paste0("[", round(l_95_percent_ci, 2), ", ", round(u_95_percent_ci, 2), "]"),
         term = clean_varnames(term)) %>% 
  select(-matches("percent")) %>% 
  relocate(term, estimate, est_error, ci95) %>% 
  gt(rowname_col = "term") %>% 
  fmt_number(columns = vars(estimate, est_error, rhat, bulk_ess, tail_ess)) %>% 
  cols_label(estimate = "Estimate", est_error = "SE", ci95 = "95% CrI", rhat = "R-hat", bulk_ess = "Bulk ESS", tail_ess = "Tail ESS")

```



```{r posterior_draws, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.cap="Posterior distribution of the extended model's (fit3_phon) coefficients. The X-axis represents all the values that each coefficient can take. The Y-axis represents the probability density at each value, i.e., the probability of the coefficient taking a specific value. Grey bars colour-code highest density intervals (HDI) of different width. Each interval indicates the narrowest interval that can be define within each distribution capturing a given proportion of the probability mass (e.g., given our data there is a 95% probability that the true value of a coefficient lies within the 95% HDI interval."}

posterior %>% 
  mutate(.variable = clean_varnames(.variable)) %>% 
  ggplot(aes(.value, .variable)) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  stat_slab(show.legend = FALSE, fill = "grey30") + 
  stat_interval(.width = c(0.95, 0.89, 0.67, 0.5), position = position_nudge(y = -0.2)) +
  labs(x = "Estimate", y = "Coefficient", colour = "Credible interval",
       title = "Posterior distribution of coefficients of fixed effects") +
  scale_colour_brewer(palette = "Oranges") +
  theme_classic() +
  theme(panel.grid.major.y = element_line(colour = "grey"),
        legend.position = "top",
        legend.key = element_rect(fill = "transparent", colour = NA),
        axis.text = element_text(colour = "black"),
        axis.title.y = element_blank())

```


## Posterior predictions


```{r posterior_predictions, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.cap="Predicted probability of correct translation across different measures of phonological similarity scores. Predictions were generated by sampling 1000 random draws from the posterior distribution of each predictor in the extended model (fit3_phon)."}

predictions %>%
  ggplot(aes(similarity_phon, .value, colour = group)) +
  geom_point(data = accuracy, aes(y = correct_coded), shape = 1, alpha = 0.1) +
  geom_line(aes(group = .draw), alpha = 0.25, colour = "grey") +
  stat_summary(fun = "mean", geom = "line", colour = "black", size = 1) +
  labs(x = "Phonological similarity", y = "Probability of correct translation",
       fill = "PTHN", colour = "Group") +
  theme_classic() +
  theme(axis.text = element_text(colour = "black"))
```


## Random effects


```{r group_effects, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.cap="Group-level effects. We specified a maximal random effects structure. As a result, intercepts and slopes were estimated for each group. This figure shows how the estimated intercepts and slopes varied across groups. There are not any remarkable differences across groups, except for the slope of phonological similarity. The accuracy of Spanish-native speakers translating from Catala (SPA-CAT) was slightly boosted by the phonological similarity between translation equivalents in comparison with the rest of the groups (ENG-SPA and ENG-CAT)."}

group_effects %>%
  mutate(param = clean_varnames(param)) %>% 
  ggplot(aes(.value, group)) +
  facet_wrap(~param, scales = "free") +
  stat_interval(.width = c(0.95, 0.89, 0.67, 0.50)) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  labs(x = "Estimate", y = "Group", colour = "HDI (%)") +
  scale_colour_brewer() +
  theme_classic() +
  theme(legend.position = "top",
        panel.grid.major.x = element_line(colour = "grey", linetype = "dotted"),
        axis.title.y = element_blank(),
        axis.text = element_text(colour = "black"))


```



```{r correlations, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.cap="Pairwise correlations between group-level effects. This figure displays the correlation between the posterior draws of all pairs of coefficients in the random effects structure. All 95% HDI of the correlation included zero, and no remarkable differences can be found across groups."}

corrs %>% 
  mutate(.variable = str_remove(.variable, "cor_group__"),
         .variable = str_replace(.variable, "__" , " - "),
         .variable = clean_varnames(.variable)) %>% 
  ggplot(aes(.value, .variable)) +
  stat_interval(.width = c(0.95, 0.89, 0.67, 0.50)) +
    geom_vline(xintercept = 0, linetype = "dashed") +
  labs(x = "Estimate", y = "Group", colour = "HDI (%)") +
  scale_colour_brewer(palette = "Oranges") +
  theme_classic() +
  theme(legend.position = "top",
        panel.grid.major.x = element_line(colour = "grey", linetype = "dotted"),
        axis.title.y = element_blank(),
        axis.text = element_text(colour = "black"))


```



