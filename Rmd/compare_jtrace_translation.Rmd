---
title: "Comparing jTRACE Output with Translation Elicitation Task"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(tidyverse)
library(ggplot2)
library(janitor) # for cleaning colnames
library(stringdist)
library(brms) # for fitting Bayesian models
library(tidybayes) # for processing Bayesian models
library(here)

# set parameters
set.seed(888) # for reproducibility
options(mc.cores = 4, chains = 4, iter = 500, seed = 888)
source(here("R", "utils.R"))
```


```{r load jtrace output}
filedir <- "data/" 
# directory with save files (
  ## 1 file per input word, with 1 output word per column
  ## files should be named with input word orthography and language (e.g. "gato_spanish.xlsx")
  ## files should be xlsx (csv doesn't deal well with special characters like ^ and @)
  ## folder should not contain any other files

# Note: it's effortful to have to convert to xlsx (jTRACE doesn't allow direct xlsx export), but it's the most reliable method to preserve special characters I've found so far. Would welcome ideas

# Export jTRACE output with Top 100 items and 100 cycles (arbritary value)
# Max ad-hoc activation


fnames <- dir(filedir) # extract list of file names in directory

trace_output <- data.frame() # create empty data frame

# for loop to extract highest activations for each input word
for (i in 1:length(fnames)){
  filename <- paste(filedir, fnames[i], sep = "") # get file name
  temp <- read_excel(filename) # read file
  
  temp <- apply(temp,2,max) # get highest value in each column
  temp <- as.data.frame(temp)
  temp <- cbind(newColName = rownames(temp), temp) # change index column (which has output items) into column 1 for easier organisation
  rownames(temp) <- 1:nrow(temp)
  names(temp)[1] <- "trace_eng" # (rename col) output item
  names(temp)[2] <- "trace_activation" # (rename col) max activation value

  temp <- temp %>%
    filter(!trace_eng == "cycle") %>% # remove row corresponding to cycle number
    mutate(input = fnames[i]) %>% # specify input word
    arrange(desc(trace_activation)) %>%
    filter(!trace_activation <= 0) # remove low activation (maybe even apply a higher threshold? TBD)
  
  trace_output <- bind_rows(trace_output, temp)
}

trace_output <- trace_output %>%
  mutate(input = str_remove(input, ".xlsx")) %>%
  separate(input, c("input", "language"), "_")


```


```{r match word}

# LEXICON / OUTPUT
# xlsx file with 1 column for TRACE transcriptions and 1 column for orthography (English words) 
df_lexicon <- read_excel("trace_transcription.xlsx", sheet = "lexicon") %>%
  select(trace_eng, ort_eng) %>%
  unique()

# Match the jTRACE output transcriptions with their orthography
trace_output_phon <- left_join(trace_output, df_lexicon, by = c("trace_eng")) %>%
  rename(output_word = ort_eng)

# INPUT -------------------------------------
# jTRACE transcriptions of input
df_trial_phon <- read_excel("trace_transcription.xlsx", sheet = "trials") %>%
  select(ort_presented, trace_presented, language) %>%
  mutate(language = tolower(language)) %>%
  unique()

trace_output_phon <- left_join(trace_output_phon, df_trial_phon, by = c("input" = "ort_presented", "language"))


```


```{r load clearpond}

df_clearpond <- read_excel("trace_transcription.xlsx", sheet = "clearpond") %>%
  select(Word, Freq_per_million, PTHN) %>%
  clean_names() %>%
  rename(frequency = freq_per_million) %>%
  unique() %>%
  mutate(word = tolower(word))


trace_output_stats <- left_join(trace_output_phon, df_clearpond, by = c("output_word" = "word")) %>%
  mutate(n_char = ifelse(nchar(trace_eng) > nchar(trace_presented), nchar(trace_eng), nchar(trace_presented)),
    lv = stringsim(trace_eng, trace_presented, method = "lv"))

```

#### Model predictions for jTRACE output

```{r run models jtrace}

responses <- trace_output_stats %>% 
    # transform relative frequency to Zipf score
    mutate(frequency_zipf = relative_to_zipf(frequency)) %>% 
    # center predictors
    mutate_at(
        vars(lv, pthn, frequency),
        function(x) scale(x, center = TRUE, scale = TRUE)[,1]) %>% 
    complete() %>% 
    as_tibble() %>% 
    drop_na(lv, pthn, frequency_zipf)

# fit models ----
# formula
f_0 <- bf(trace_activation ~ 1 + frequency, family = bernoulli(link = "logit"))
f_1 <- bf(trace_activation ~ 1+ frequency + pthn, family = bernoulli(link = "logit"))
f_2 <- bf(trace_activation ~ 1 + frequency + pthn*lv, family = bernoulli(link = "logit"))

# prior
priors <- c(
    prior(normal(0, 3), class = "Intercept"),
    prior(normal(0, 3), clas = "b"),
    prior(cauchy(0, 3), class= "sd"),
    prior(lkj(5), class = "cor")
)


# fit models
fit_0 <- brm(f_0, data = responses, prior = priors[c(1, 3),], backend = "cmdstanr",
             file = here("Results", "fit_responses_jtrace_0.rds"))
fit_1 <- brm(f_1, data = responses, prior = priors, backend = "cmdstanr",
             file = here("Results", "fit_responses_jtrace_1.rds"))
fit_2 <- brm(f_2, data = responses, prior = priors, backend = "cmdstanr",
             file = here("Results", "fit_responses_jtrace_2.rds"))

# model comparison
# model fit is the best
loos <- list(fit_0 = loo(fit_0), fit_1 = loo(fit_1), fit_2 = loo(fit_2))
loos_comp <- loo_compare(loos$fit_0, loos$fit_1, loos$fit_2)


```


## Comparing against Translation Task


```{r load translation task}

# Cleaned file with participant answers, 1 row per trial per participant
TranslationTask <- read.csv("translation_engdata_cleaned.csv") %>%
  mutate(test_language = tolower(test_language))

# count the number of participants who gave each answer in response to a given trial
df_answer <- TranslationTask %>%
  group_by(test_language, word, answer) %>%
  summarise(n_participant = n(), .groups = "drop") %>%
  group_by(test_language, word) %>%
  mutate(pct_participant = n_participant/sum(n_participant)*100) #%>%
#  filter(!n_participant == 1) # remove answers only given by 1 participant as idiosyncratic answers?

```



### Predicting participant response by jTRACE

```{r match data, warning = FALSE}

# Predicting participant response by jTRACE

df_match <- full_join(trace_output, df_answer, by = c("input" = "word", "output_word" = "answer", "language" = "test_language")) %>%
  semi_join(., trace_output, by = c("input", "language"))

# answers
print("Presented words and the answer that was given by the most number of participants for that trial")

# If "trace_activation" is <NA>, the word is not in the currently-used jTRACE lexicon
df_match %>%
  filter(language == "spanish") %>% 
  arrange(input, desc(pct_participant)) %>%
  group_by(input) %>%
  slice(1) %>%
  select(input, output_word, pct_participant, trace_activation) %>%
  arrange(desc(pct_participant))

df_match %>%
  filter(language == "catalan") %>% 
  arrange(input, desc(pct_participant)) %>%
  group_by(input) %>%
  slice(1) %>%
  select(input, output_word, pct_participant, trace_activation) %>%
  arrange(desc(pct_participant))


# if no data for a given output word is available in df_answer, it means no participants gave that word as a response - recode as 0
df_match$pct_participant[is.na(df_match$pct_participant)] <- 0

# if no data for a given output word is available in trace output, it means that activation is outside of Top 100 words and/or below 0
df_match$trace_activation[is.na(df_match$trace_activation)] <- 0

# However, this is also constrained by the size of TRACE's lexicon, so subset only the words that do appear in the lexicon
df_match_trace <- semi_join(df_match, df_transcription, by = c("output_word" = "ort_eng"))

```

### Plot relationship

```{r plot, warning = FALSE}

# plot
ggplot(df_match_trace, aes(x = trace_activation, y = pct_participant)) +
  geom_smooth() +
  geom_point() +
  ggtitle("jTRACE activation against % participants who gave word as response")

# correlation test
cor.test(df_match_trace$trace_activation, df_match_trace$pct_participant)


# plot by word
ggplot(df_match_trace, aes(x = trace_activation, y = pct_participant)) +
  geom_smooth() +
  geom_point() +
  xlab("jTRACE activation value for the word") +
  ylab("% participants who responded with the word") +
  ggtitle("jTRACE activation against % participants who gave word as response") +
  facet_wrap(language~input)


```
