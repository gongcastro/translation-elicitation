---
title: "Translation Elicitation"
output:
  html_document:
    df_print: paged
    toc: true
    toc_depth: 2
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = TRUE,
  warning = TRUE, 
  cache.extra = knitr::rand_seed,
  out.width = "100%",
  results = "asis",
  dev.args = list(png = list(type = "cairo"))
)
options(knitr.kable.NA = '-')
```


```{r prepare, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}

# load packages
library(tidyverse)
library(gt)
library(lubridate)
library(ggdist)
library(readxl)
library(tidytext)
library(brms)
library(tidybayes)
library(patchwork)
library(mice)
library(here)

# set params
source(here("R", "utils.R"))

# import data
trials <- readRDS(here("Data", "trials.rds"))
participants <- readRDS(here("Data", "participants.rds"))
responses <- readRDS(here("Data", "accuracy.rds"))
jtrace <- readRDS(here("Data", "jtrace.rds"))

# import models
fit_jtrace <- readRDS(here("Results", "fit_jtrace.rds"))
fit_responses <- readRDS(here("Results", "fit.rds"))
fit_responses_coefs <- readRDS(here("Results", "coefficients.rds")) %>% 
  select(term, estimate, std.error, conf.low, conf.high)



```


# Experimental task: Translation Elicitation

## Methods


### Participants {.tabset .tab-pills}

```{r participants_coded}
participants_coded <- participants %>% 
  mutate(valid_participant = ifelse(valid_participant, "Valid", "Not valid"))
```

We collected data from `r format(as_date(min(participants$date)), "%B %dth %Y")` to `r format(as_date(max(participants$date)), "%B %dth %Y")`. We tested `r length(unique(participants$participant))` participants. `r length(unique(participants$participant[participants$group=="ENG-SPA"]))` were English natives tested in Spanish, `r length(unique(participants$participant[participants$group=="ENG-CAT"]))` were English natives tested in Catalan, and `r length(unique(participants$participant[participants$group=="SPA-CAT"]))` were Spanish natives tested in Catalan. `r sum(!participants$valid_participant)` failed to meet all the inclusion criteria and were excluded from further analyses.

Participants were included if^[We originally planned to exclude participants that reported any visual impairment that glasses would not correct. This item was phrased as Do you have normal or corrected-to-normal VISION? (Yes/No) in English, and as ¿Tienes problemas de VISIÓN que unas gafas o lentes de contacto NO corrijan? (Sí/No). Surprisingly, the proportion of Spanish participants that reported visual impairment was implausibly large (n = 6, 18.18%). This is possibly due to some participants using glasses daily and not having read the item until the end, where it is indicated that the use of glasses is considered as normal vision]:

* Aged 18 to 25 years
* Did not report being fluent in Catalan, Spanish, or Italian
* Provided at least 80% of the presented trials
* Did not report motor, auditory or visual (other than wearing glasses) problems

Trials were considered valid if:

* Participant did not leave a blank response
* Participant took longer than 10 seconds to respond

#### Summary

```{r participants_summary, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

ggplot(participants_coded, aes(group, fill = valid_participant)) +
  geom_bar() +
  labs(x = "Group", y = "# participants", fill = "Valid?") +
  theme_custom() +
  theme(
    legend.title = element_blank(),
    legend.position = "top",
    axis.title.x = element_blank(),
    panel.grid.major.y = element_line(linetype = "dotted", colour = "grey")
  )

```

#### Valid trials

```{r participants_trials, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

participants_coded %>% 
  filter(valid_participant=="Valid") %>% 
  select(participant, group, n, n_valid) %>%
  mutate(valid_prop = n_valid/n) %>% 
  ggplot(aes(group, valid_prop, fill = group, colour = group)) +
  geom_violin() +
  geom_point(shape = 1, stroke = 1, alpha = 0.5, position = position_jitter(width = 0.1),
             colour = "black") +
  geom_boxplot(colour = "black", fill = "white", width = 0.05, outlier.color = NA) +
  labs(x = "Group", y = "Valid trials", fill = "Group", colour = "Group") +
  scale_y_continuous(limits = c(0.8, 1), labels = scales::percent) +
  theme_custom() +
  theme(
    legend.title = element_blank(),
    legend.position = "top",
    axis.title.x = element_blank(),
    panel.grid.major.y = element_line(linetype = "dotted", colour = "grey")
  ) 
```

#### Demographic information

```{r participants_demo, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
participants_valid <- filter(participants_coded, valid_participant=="Valid")
p_sex <- ggplot(participants_valid, aes(group, fill = sex)) +
  geom_bar() +
  labs(x = "Group", y = "# participants", fill = "Sex") +
  theme(axis.title.x = element_blank())

p_age <- ggplot(participants_valid, aes(as.factor(age), fill = group, colour = group)) +
  geom_bar() +
  labs(x = "Age (years)", y = "# participants", fill = "Group", colour = "Group")

(p_sex + p_age) &
  plot_layout() &
  plot_annotation() &
  theme_custom() +
  theme(
    legend.position = "top",
    legend.title = element_blank(),
    panel.grid.major.y = element_line(linetype = "dotted", colour = "grey")
  )

```

#### Second language

```{r participants_l2, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

participants_valid %>% 
  count(group, l2) %>% 
  mutate(l2 = reorder_within(l2, n, within = group)) %>% 
  ggplot(aes(x = reorder(l2, -n), n,  fill = l2)) +
  facet_wrap(~group, scales = "free_x") +
  geom_col() +
  labs(x = "L2", y = "# participants", fill = "L2") +
  scale_x_reordered() +
  theme_custom() +
  theme(
    legend.position = "none",
    panel.grid.major.y = element_line(colour = "grey", linetype = "dotted"),
    axis.text.x = element_text(angle = 90)
  )

```


#### Language profile proficiency

```{r participants_proficiency, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

participants_valid %>% 
  select(participant, group, catalan_oral, spanish_oral, catalan_written, spanish_written) %>% 
  mutate_at(vars(catalan_oral, spanish_oral, catalan_written, spanish_written), replace_na, 0) %>% 
  pivot_longer(c(catalan_oral, spanish_oral, catalan_written, spanish_written),
               names_to = "type", values_to = "score") %>% 
  separate(type, c("language", "modality"), sep = "_") %>% 
  mutate_at(vars(language, modality), str_to_sentence) %>%
  ggplot(aes(as.integer(score), fill = language)) +
  facet_grid(modality~group) +
  geom_bar() +
  labs(y = "# participants", x = "Self-reportd proficiency (0-5)", fill = "Language") +
  scale_x_continuous(limits = c(0, 5)) +
  coord_flip() +
  theme_custom() +
  theme(
    legend.position = "none",
    panel.grid.major.y = element_line(colour = "grey", linetype = "dotted")
  )

```

#### {-}


### Stimuli {.tabset .tab-pill}

```{r trials_coded, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE,  include=FALSE}
trials_coded <- trials %>% 
  mutate(
    test_language = ifelse(group=="ENG-SPA", "Spanish", "Catalan"),
    zipf = log10(frequency)+3,
    pthn_log = log(pthn),
    overlap_stress = ifelse(overlap_stress==1, "Same", "Different")
  )
```

#### Lexical frequency

```{r trials_frequency, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
trials_coded %>% 
  ggplot(aes(zipf, fill = test_language)) +
  geom_histogram(bins = 25) +
  labs(x = "Lexical frequency (Zipf score)\nExtracted from CLEARPOND database", y = "# trials", fill = "Test language") +
  theme_custom() +
  theme(
    panel.grid.major.y = element_line(colour = "grey", linetype = "dotted")
  )

```

#### PTHN

```{r trials_pthn, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
trials_coded %>% 
  count(test_language, pthn) %>% 
  ggplot(aes(reorder(as.factor(pthn), -n), n, fill = test_language)) +
  geom_col(position = position_dodge()) +
  labs(x = "# Phonological neighbours with higher lexical frequency\nExtracted from CLEARPOND database", y = "# trials", fill = "Test language") +
  theme_custom() +
  theme(
    legend.position = "top",
    panel.grid.major.y = element_line(colour = "grey", linetype = "dotted")
  )

```

#### Vowel and consonant similarity

```{r trials_similarity, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
trials_coded %>% 
  select(trial_id, group, ends_with("_ratio")) %>% 
  pivot_longer(ends_with("_ratio"), names_to = "type", values_to = "ratio") %>% 
  mutate(type = str_to_sentence(str_remove(type, "_ratio"))) %>% 
  ggplot(aes(group, ratio, fill = group, colour = group)) +
  facet_wrap(~type) +
  geom_violin() +
  geom_point(shape = 1, stroke = 1, position = position_jitter(width = 0.1), colour = "black", alpha = 0.25) +
  geom_boxplot(colour = "black", fill = "white", width = 0.1, size = 0.75) +
  labs(x = "Grouop", y = "Similarity", fill = "Test language") +
  scale_y_continuous(limits = c(0, 1), labels = scales::percent) +
  theme_custom() +
  theme(
    legend.position = "none",
    panel.grid.major.y = element_line(colour = "grey", linetype = "dotted")
  )

```

#### Phonological onset

```{r trials_onset, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
trials_coded %>% 
  select(trial_id, group, onset) %>% 
  ggplot(aes(group, fill = onset, colour = onset)) +
  geom_bar(position = position_dodge(width = 0.9)) +
  labs(x = "Group", y = "# trials", fill = "Phonological onset", colour = "Phonological onset") +
  theme_custom() +
  theme(
    legend.position = "top",
    panel.grid.major.y = element_line(colour = "grey", linetype = "dotted")
  )
```

#### Stress position

```{r trials_stress, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
trials_coded %>% 
  select(trial_id, group, overlap_stress) %>% 
  ggplot(aes(group, fill = overlap_stress, colour = overlap_stress)) +
  geom_bar(position = position_dodge(width = 0.9)) +
  labs(x = "Group", y = "# trials", fill = "Same stress position?", colour = "Same stress position?") +
  theme_custom() +
  theme(
    legend.position = "top",
    panel.grid.major.y = element_line(colour = "grey", linetype = "dotted")
  )
```

#### {-}

### Design


### Data analysis


## Results {.tabset .tab-pill}

### Accuracy by item

```{r accuracy_item, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
responses_item <- responses %>%
  group_by(group, word) %>%
  summarise(
    correct_sum = sum(correct, na.rm = TRUE),
    correct_n = sum(!is.na(correct), na.rm = TRUE),
    .groups = "drop"
  ) %>% 
  mutate(
    correct_prop = prop_adj(correct_sum, correct_n),
    correct_se = prop_adj_se(correct_sum, correct_n),
    word_label = reorder_within(word, by = correct_prop, within = group)
  )

ggplot(responses_item, aes(reorder(word_label, correct_prop), correct_prop, ymin = correct_prop-correct_se, ymax = correct_prop+correct_se, colour = group)) +
  facet_wrap(~group, scales = "free_y") +
  geom_hline(yintercept = 0.5, colour = "red") +
  geom_errorbar() +
  geom_point(size = 0.5) +
  labs(y = "Correct responses", x = "Word", colour = "Group") +
  coord_flip() +
  scale_y_continuous(limits = c(0, 1), labels = scales::percent) +
  theme_custom() +
  theme(
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    axis.text.x = element_text(size = 9),
    panel.grid.major.x = element_line(colour = "grey", linetype = "dotted")
  )

```

### Accuracy by participant

```{r responses_participant, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
responses_participant <- responses %>%
  group_by(group, participant) %>%
  summarise(
    correct_sum = sum(correct, na.rm = TRUE),
    correct_n = sum(!is.na(correct), na.rm = TRUE),
    .groups = "drop"
  ) %>% 
  mutate(
    correct_prop = prop_adj(correct_sum, correct_n),
    correct_se = prop_adj_se(correct_sum, correct_n),
    participant_label = reorder_within(participant, by = correct_prop, within = group)
  )

ggplot(responses_participant, aes(reorder(participant_label, correct_prop), correct_prop, ymin = correct_prop-correct_se, ymax = correct_prop+correct_se, colour = group)) +
  facet_wrap(~group, scales = "free_y") +
  geom_hline(yintercept = 0.5, colour = "red") +
  geom_errorbar(width = 0.5) +
  geom_point(size = 1) +
  labs(y = "Correct responses", x = "Participant", colour = "Group") +
  coord_flip() +
  scale_y_continuous(limits = c(0, 1), labels = scales::percent) +
  theme_custom() +
  theme(
    legend.position = "top",
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    axis.text.x = element_text(size = 9),
    panel.grid.major.x = element_line(colour = "grey", linetype = "dotted")
  )

```

### Bayesian regression model {.tabset .tab-pill}

#### Model details

We fitted a Bayesian multilevel regression model using the R package `brms` [@burkner2017brms], with correct responses (`correct`, 0 is incorrect response, 1 if correct response) as the response variable with a Bernoulli distribution and a logit link function. We modelled the probability of an average participant providing a correct response, conditional to a set of predictors (aka. fixed effects):

* PTHN (`pthn`, 0-Inf): number of phonological neighbours with higher frequency of the target word. Extracted from the CLEARPOND database.
* Lexical frequency (`frequency`, 0-Inf): lexical frequency (counts per million) of the target word. Extracted from the SUBTLEX database (via CLEAPOND).
* Vowel similarity (`vowel_ratio`, 0-1): edit distance between the sequence of vowels of the presented word  and the target word. Computed using custom code.
* Consonant similarity (`consonant_ratio`, 0-1): edit distance between the sequence of consonants of the presented word and the target word. Computed using custom code.
* Shared phonological onset (`onset`, 0 or 1): do the presented word and the target word share phonological onset? Manually coded.
* Share stress position (`overlap_stress`, 0 or 1): are the presented word and the target word stressed at the same position? Manually coded.

We also added participants (`participants`) and words (`word`) as grouping variables (aka., random effects), therefore adjusting the model to each participant and word. We specified random intercepts for both grouping variables, and random slopes for the fixed effects within the `participant` grouping variable.

We model was implemented using the following formula:

```
correct ~ pthn + frequency + consonant_ratio + vowel_ratio + onset + overlap_stress + (1 + pthn + frequency + consonant_ratio + vowel_ratio + onset + overlap_stress | participant) + (1 | trial_id)
```

The estimation of the model was performed using Bayesian inference via Hamiltonian Monte-Carlo in Stan [@carpenter2017stan], with 4 chains, 2,000 intertions each. The output of this model is the approximated posterior distribution of all the parameters estimated, therefore indicating the probability of each combination of values of the parameters, conditional to the observed data. 


#### Stan code

Stan code generated by `brms`:

```{stan stan_model, echo=TRUE, output.var="model"}
// generated with brms 2.15.0
functions {
 /* compute correlated group-level effects
  * Args: 
  *   z: matrix of unscaled group-level effects
  *   SD: vector of standard deviation parameters
  *   L: cholesky factor correlation matrix
  * Returns: 
  *   matrix of scaled group-level effects
  */ 
  matrix scale_r_cor(matrix z, vector SD, matrix L) {
    // r is stored in another dimension order than z
    return transpose(diag_pre_multiply(SD, L) * z);
  }
}
data {
  int<lower=1> N;  // total number of observations
  int Y[N];  // response variable
  int<lower=1> K;  // number of population-level effects
  matrix[N, K] X;  // population-level design matrix
  // data for group-level effects of ID 1
  int<lower=1> N_1;  // number of grouping levels
  int<lower=1> M_1;  // number of coefficients per level
  int<lower=1> J_1[N];  // grouping indicator per observation
  // group-level predictor values
  vector[N] Z_1_1;
  vector[N] Z_1_2;
  vector[N] Z_1_3;
  vector[N] Z_1_4;
  vector[N] Z_1_5;
  vector[N] Z_1_6;
  vector[N] Z_1_7;
  int<lower=1> NC_1;  // number of group-level correlations
  // data for group-level effects of ID 2
  int<lower=1> N_2;  // number of grouping levels
  int<lower=1> M_2;  // number of coefficients per level
  int<lower=1> J_2[N];  // grouping indicator per observation
  // group-level predictor values
  vector[N] Z_2_1;
  int prior_only;  // should the likelihood be ignored?
}
transformed data {
  int Kc = K - 1;
  matrix[N, Kc] Xc;  // centered version of X without an intercept
  vector[Kc] means_X;  // column means of X before centering
  for (i in 2:K) {
    means_X[i - 1] = mean(X[, i]);
    Xc[, i - 1] = X[, i] - means_X[i - 1];
  }
}
parameters {
  vector[Kc] b;  // population-level effects
  real Intercept;  // temporary intercept for centered predictors
  matrix[M_1, N_1] z_1;  // standardized group-level effects
  cholesky_factor_corr[M_1] L_1;  // cholesky factor of correlation matrix
  vector<lower=0>[M_2] sd_2;  // group-level standard deviations
  vector[N_2] z_2[M_2];  // standardized group-level effects
}
transformed parameters {
  vector<lower=0>[M_1] sd_1;  // group-level standard deviations
  matrix[N_1, M_1] r_1;  // actual group-level effects
  // using vectors speeds up indexing in loops
  vector[N_1] r_1_1;
  vector[N_1] r_1_2;
  vector[N_1] r_1_3;
  vector[N_1] r_1_4;
  vector[N_1] r_1_5;
  vector[N_1] r_1_6;
  vector[N_1] r_1_7;
  vector[N_2] r_2_1;  // actual group-level effects
  sd_1 = rep_vector(1, rows(sd_1));
  // compute actual group-level effects
  r_1 = scale_r_cor(z_1, sd_1, L_1);
  r_1_1 = r_1[, 1];
  r_1_2 = r_1[, 2];
  r_1_3 = r_1[, 3];
  r_1_4 = r_1[, 4];
  r_1_5 = r_1[, 5];
  r_1_6 = r_1[, 6];
  r_1_7 = r_1[, 7];
  r_2_1 = (sd_2[1] * (z_2[1]));
}
model {
  // likelihood including constants
  if (!prior_only) {
    // initialize linear predictor term
    vector[N] mu = Intercept + rep_vector(0.0, N);
    for (n in 1:N) {
      // add more terms to the linear predictor
      mu[n] += r_1_1[J_1[n]] * Z_1_1[n] + r_1_2[J_1[n]] * Z_1_2[n] + r_1_3[J_1[n]] * Z_1_3[n] + r_1_4[J_1[n]] * Z_1_4[n] + r_1_5[J_1[n]] * Z_1_5[n] + r_1_6[J_1[n]] * Z_1_6[n] + r_1_7[J_1[n]] * Z_1_7[n] + r_2_1[J_2[n]] * Z_2_1[n];
    }
    target += bernoulli_logit_glm_lpmf(Y | Xc, mu, b);
  }
  // priors including constants
  target += normal_lpdf(b | 0, 1);
  target += normal_lpdf(Intercept | 0, 1);
  target += std_normal_lpdf(to_vector(z_1));
  target += lkj_corr_cholesky_lpdf(L_1 | 5);
  target += cauchy_lpdf(sd_2 | 0, 3)
    - 1 * cauchy_lccdf(0 | 0, 3);
  target += std_normal_lpdf(z_2[1]);
}
generated quantities {
  // actual population-level intercept
  real b_Intercept = Intercept - dot_product(means_X, b);
  // compute group-level correlations
  corr_matrix[M_1] Cor_1 = multiply_lower_tri_self_transpose(L_1);
  vector<lower=-1,upper=1>[NC_1] cor_1;
  // extract upper diagonal of correlation matrix
  for (k in 1:M_1) {
    for (j in 1:(k - 1)) {
      cor_1[choose(k - 1, 2) + j] = Cor_1[j, k];
    }
  }
}
```

```{r responses_coded, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
responses_coded <- responses %>% 
  # typos are considered correct responses
  mutate_at(vars(onset, overlap_stress, group), as.factor) %>% 
  # center predictors
  mutate_at(
    vars(consonant_ratio, vowel_ratio, pthn, frequency),
    function(x) scale(x, center = TRUE, scale = TRUE)[,1]) %>% 
  # impute missing data
  mice(m = 5, print = FALSE, method = "pmm") %>% 
  complete() %>% 
  as_tibble() %>% 
  arrange(trial_id, group)
```

#### Fixed coefficients

```{r coefs_fixed_table, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
summary(fit_responses)$fixed %>% 
  as.data.frame() %>%
  rownames_to_column("term") %>% 
  mutate(
    Estimate = ifelse(term=="Intercept", inv_logit_scaled(Estimate), Estimate/4),
    `l-95% CI` = ifelse(term=="Intercept", inv_logit_scaled(`l-95% CI`), `l-95% CI`/4),
    `u-95% CI` = ifelse(term=="Intercept", inv_logit_scaled(`u-95% CI`), `u-95% CI`/4),
    Est.Error = ifelse(term=="Intercep)", inv_logit_scaled(Est.Error), Est.Error/4)
  ) %>% 
  gt() %>% 
  fmt_percent(2:5) %>% 
  fmt_number(6:6, decimals = 2) %>% 
  fmt_number(7:8, decimals = 0) %>% 
  cols_merge(vars("l-95% CI", "u-95% CI"), pattern = "[{1}, {2}]") %>% 
  cols_label(
    term = md("**Predictor**"),
    Estimate = md("**Mean**"),
    Est.Error = md("**SEM**"),
    "l-95% CI" = md("**95\\% CrI**"),
    Rhat = md("**Rhat**"),
    Bulk_ESS = md("**Bulk ESS**"),
    Tail_ESS = md("**Tail ESS**")
  ) %>% 
  tab_footnote(
    footnote = "Transformed using the inverse logit to get the average probability of correct response",
    locations = cells_body(columns = "term", rows = term=="(Intercept)")
  ) %>% 
  tab_footnote(
    footnote = "Transformed using the divide-by-four- rule to get the maximum change in probability of correct response, associated with a unit increase in this variable.",
    locations = cells_body(columns = "term", rows = term %in% c("pthn", "frequency", "consonant_ratio", "vowel_ratio", "onset1", "overlap_stress1"))
  ) %>% 
  tab_footnote(
    footnote = "ESS: Effective sample size",
    locations = cells_column_labels(columns = c("Bulk_ESS", "Tail_ESS"))
  ) %>% 
  cols_align(
    align = c("center"),
    columns = 2:4
  )
```


```{r post_fix, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
post <- gather_draws(fit_responses, `b_.*`, regex = TRUE) %>% 
  mutate(.value = ifelse(.variable=="b_Intercept", inv_logit_scaled(.value), .value/4))

ggplot(post, aes(.value, fill = .variable)) +
  facet_wrap(~.variable, scales = "free") +
  geom_vline(xintercept = 0, colour = "red") +
  stat_halfeye() +
  labs(x = "Value", y = "Posterior probability density", fill = "Variable") +
  theme_custom() +
  theme(
    legend.position = "none",
    axis.text = element_text(size = 7),
    panel.grid.major.x = element_line(colour = "grey", linetype = "dotted"),
    panel.grid.major.y = element_line(colour = "grey", linetype = "dotted")
  )
```


#### Random effects

```{r post_re, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
post_re <- gather_draws(fit_responses, r_participant[participant, .param]) %>% 
  mean_qi() %>% 
  ungroup() %>% 
  left_join(select(participants, participant, group)) %>% 
  arrange(group, participant, .param)

ggplot(post_re, aes(.value, sort(as.factor(participant)), xmin = .lower, xmax = .upper, colour = group)) +
  facet_grid(group~.param, scales = "free_y") +
  geom_errorbarh(height = 0.5, alpha = 0.75) +
  geom_point(size = 0.1, shape = 4) +
  geom_vline(xintercept = 0, colour = "red") +
  labs(x = "Participant-level adjustment", y = "Participant", colour = "Group") +
  theme_custom() +
  theme(
    legend.position = "top",
    legend.title = element_blank(),
    panel.grid.major.x = element_line(colour = "grey", linetype = "dotted"),
    axis.text.x = element_text(size = 9),
    axis.text.y = element_blank(),
    axis.ticks = element_blank()
  )
```


#### Marginal effects

```{r emmeans, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
nd <- expand_grid(
  pthn = seq(
    min(responses_coded$pthn, na.rm = TRUE),
    max(responses_coded$pthn, na.rm = TRUE),
    by = 0.1
  ),
  onset = unique(responses_coded$onset),
  overlap_stress = unique(responses_coded$overlap_stress),
  vowel_ratio = c(-1, 1),
  consonant_ratio = c(-1, 1)
) %>% 
  mutate(frequency = 0)

m <- add_fitted_draws(nd, fit_responses, n = 20, re_formula = NA) %>% 
  mutate_at(vars(ends_with("_ratio")),
            function(x) ifelse(x>0, paste0(x, " SD"), paste0("-", x, " SD")))

ggplot(m, aes(pthn, .value, 
              colour = interaction(consonant_ratio, vowel_ratio, sep = "/"),
              fill = interaction(consonant_ratio, vowel_ratio, sep = "/"))) +
  facet_grid(~overlap_stress~onset) +
  stat_lineribbon(.width = 0.95, alpha = 0.25, size = 0) +
  stat_summary(fun = mean, geom = "line", size = 1) +
  labs(x = "Phonological neighbourhood density\n(higher frequency neighbours)",
       y = "P(Correct)", colour = "Consonant/Vowel similarity",
       fill = "Consonant similarity / Vowel similarity") +
  theme_custom() +
  theme(
    legend.position = "top",
    panel.grid = element_line(colour = "grey", linetype = "dotted")
  )
```

#### {-}

### {-}

# TRACE simulations

## TRACE vs. human data {.tabset .tab-pill}

### TRACE activation vs. responses

```{r jtrace_all_plot, echo=FALSE, warning=FALSE}
ggplot(jtrace, aes(x = activation, y = pct_participant)) +
  geom_smooth() +
  geom_point(shape = 1, stroke = 1, alpha = 0.5) +
  labs(
    x = "jTRACE activation value for the word",
    y = "% participants who responded with the word",
    title = "jTRACE activation against % participants who gave word as response"
  ) +
  theme_custom() +
  theme(
    panel.grid.major.x = element_line(colour = "grey", linetype = "dotted"),
    panel.grid.major.y = element_line(colour = "grey", linetype = "dotted")
  )

```


### By items

```{r jtrace_word_plot, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

# plot by word
jtrace %>% 
  mutate(input_language = paste0(input, " (", language, ")")) %>% 
  ggplot(aes(x = activation, y = pct_participant)) +
  facet_wrap(~input_language) +
  geom_smooth() +
  geom_point(shape = 1, stroke = 1, alpha = 0.5) +
  labs(
    x = "jTRACE activation value for the word",
    y = "% participants who responded with the word",
    title = "jTRACE activation against % participants who gave word as response"
  ) +
  theme_custom() +
  theme(
    panel.grid.major.x = element_line(colour = "grey", linetype = "dotted"),
    panel.grid.major.y = element_line(colour = "grey", linetype = "dotted")
  )

```


### {-}

## Regression model {.tabset .tab-pill}

### Fixed coefficients

```{r jtrace_fixed_table, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
summary(fit_jtrace$fit)$fixed %>% 
  as.data.frame() %>%
  rownames_to_column("term") %>% 
  mutate(
    Estimate = ifelse(term=="Intercept", inv_logit_scaled(Estimate), Estimate/4),
    `l-95% CI` = ifelse(term=="Intercept", inv_logit_scaled(`l-95% CI`), `l-95% CI`/4),
    `u-95% CI` = ifelse(term=="Intercept", inv_logit_scaled(`u-95% CI`), `u-95% CI`/4),
    Est.Error = ifelse(term=="Intercept", inv_logit_scaled(Est.Error), Est.Error/4)
  ) %>% 
  gt() %>% 
  fmt_number(2:6, decimals = 2) %>% 
  fmt_number(7:8, decimals = 0) %>% 
  cols_merge(vars("l-95% CI", "u-95% CI"), pattern = "[{1}, {2}]") %>% 
  cols_label(
    term = md("**Predictor**"),
    Estimate = md("**Mean**"),
    Est.Error = md("**SEM**"),
    "l-95% CI" = md("**95\\% CrI**"),
    Rhat = md("**Rhat**"),
    Bulk_ESS = md("**Bulk ESS**"),
    Tail_ESS = md("**Tail ESS**")
  ) %>% 
  tab_footnote(
    footnote = "Transformed using the inverse logit to get the average probability of correct response",
    locations = cells_body(columns = "term", rows = term=="(Intercept)")
  ) %>% 
  tab_footnote(
    footnote = "Transformed using the divide-by-four- rule to get the maximum change in probability of correct response, associated with a unit increase in this variable.",
    locations = cells_body(columns = "term", rows = term %in% c("pthn", "frequency", "consonant_ratio", "vowel_ratio", "onset1", "overlap_stress1") | str_detect(term, "activation"))
  ) %>% 
  tab_footnote(
    footnote = "ESS: Effective sample size",
    locations = cells_column_labels(columns = c("Bulk_ESS", "Tail_ESS"))
  )
```

```{r jtrace_fixed_plot, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, out.width="100%"}
fit_jtrace$fixed %>%
  mutate(.value = ifelse(.variable=="b_Intercept", inv_logit_scaled(.value), .value/4)) %>% 
  ggplot(aes(.value, fill = .variable)) +
  facet_wrap(~.variable, scales = "free") +
  geom_vline(xintercept = 0, colour = "red") +
  stat_halfeye() +
  labs(x = "Value", y = "Posterior probability density", fill = "Variable") +
  theme_custom() +
  theme(
    legend.position = "none",
    panel.grid.major.x = element_line(colour = "grey", linetype = "dotted"),
    panel.grid.major.y = element_line(colour = "grey", linetype = "dotted"),
    axis.text = element_text(size = 7)
  )
```

### Random coefficients

```{r jtrace_post_re, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
re <- ranef(fit_jtrace$fit)$`group:input`
re <- rbind(Intercept = re[,,1], activation = re[,,2]) %>% 
  as.data.frame() %>% 
  rownames_to_column("term") %>% 
  mutate(
    term = str_replace(str_remove(term, ".1"), "\\.", "\\-"),
    Estimate = ifelse(term=="Intercept", inv_logit_scaled(Estimate), Estimate/4),
    Q2.5 = ifelse(term=="Intercept", inv_logit_scaled(Q2.5), Q2.5/4),
    Q97.5 = ifelse(term=="Intercept", inv_logit_scaled(Q97.5), Q97.5/4),
    Est.Error = ifelse(term=="Intercept", inv_logit_scaled(Est.Error), Est.Error/4)
  ) %>% 
  separate(term, c("group", "input"), sep = "_")
re$.param <- rep(c("Intercept", "activation"), each = 9)

ggplot(re, aes(Estimate, input, colour = input)) +
  facet_wrap(~.param) +
  geom_vline(xintercept = 0, colour = "red") +
  geom_errorbarh(aes(xmin = Estimate-Est.Error, xmax = Estimate+Est.Error), height = 0, size = 5, alpha = 0.5) +
  geom_errorbarh(aes(xmin = Q2.5, xmax = Q97.5), height = 0) +
  geom_point() +
  labs(x = "Estimate", y = "Input", colour = "Input") +
  theme_custom() +
  theme(
    legend.position = "top",
    legend.direction = "horizontal",
    axis.title.x = element_blank(),
    legend.title = element_blank(),
    panel.grid.major.x = element_line(colour = "grey", linetype = "dotted"),
    axis.text.y = element_blank(),
    axis.ticks = element_blank()
  )
```


### {-}

## Candidate pool


```{r jtrace_candidates, echo=FALSE, fig.height=30, message=FALSE, warning=FALSE, paged.print=FALSE}

trials_trace <- trials %>% 
  as_tibble() %>% 
  select(group, input = word1, target = word2, phon_trace)

# process TRACE data ----
trace <- map(
  list.files(here("Data", "jtrace"), full.names = TRUE),
  function(x){
    read_xlsx(x) %>% 
      pivot_longer(-cycle, names_to = "response", values_to = "activation")
  }
) %>%
  set_names(list.files(here("Data", "jtrace"))) %>% 
  bind_rows(.id = "target") %>% 
  separate(target, c("input", "language"), sep = "_") %>% 
  mutate(language = str_remove(language, ".xlsx"),
         language = str_to_sentence(language))

# get top candidates
trace_top <- trace %>% 
  group_by(input, language, response) %>% 
  summarise(
    activation = max(activation, na.rm = TRUE),
    .groups = "drop"
  ) %>% 
  group_by(input, language) %>% 
  slice_max(activation, n = 10) %>% 
  ungroup() %>% 
  mutate(group = ifelse(language=="Catalan", "ENG-CAT", "ENG-SPA")) %>% 
  select(-language) %>% 
  # add experimental trials
  left_join(trials_trace) %>% 
  mutate(correct = response==phon_trace) %>% 
  select(group, input, response, activation, correct)

# experimental results ----
responses_jtrace <- responses %>% 
  filter(valid_response, group %in% c("ENG-CAT", "ENG-SPA")) %>% 
  rename(response = input_text, input = word) %>% 
  count(group, input, response, correct) %>% 
  group_by(group, input) %>%
  mutate(total = sum(n), activation = n/total) %>% 
  ungroup() %>% 
  group_by(group, input) %>% 
  slice_max(order_by = activation, n = 10) %>% 
  ungroup() %>% 
  select(group, input, response, correct, activation) %>% 
  filter(input %in% trace_top$input)

# merge everything
d_jtrace <- list(TRACE = trace_top, Participants = responses_jtrace) %>% 
  bind_rows(.id = "source") %>% 
  mutate(
    # to reorder variable within panels
    input_label = paste0(input, " (", group, ")"),
    response_reordered = reorder_within(response, activation, input_label)
  ) 

ggplot(d_jtrace, aes(response_reordered, activation, fill = correct)) +
  facet_wrap(input_label~source, scales = "free_y", ncol = 2) +
  geom_col(colour = "white") +
  labs(x = "Top 10 candidates", y = "Max. TRACE activation") +
  coord_flip() +
  scale_x_reordered() +
  # scale_y_continuous(limits = c(0, 1)) +
  theme_bw() +
  theme(
    legend.position = "none"
  )

```


## {-}

# References
