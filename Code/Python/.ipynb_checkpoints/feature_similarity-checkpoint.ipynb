{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study of word similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # pandas package for importing files (e.g. from Excel)\n",
    "import numpy as np\n",
    "import difflib # package for SequenceMatcher\n",
    "from IPython.display import Markdown, display # Use Markdown\n",
    "\n",
    "#fname      = 'word_lists.xlsx'\n",
    "#wordsheet  = 'English-French'\n",
    "#wordsheet  = 'English-Dutch'\n",
    "#wordsheet  = 'English-Spanish'\n",
    "#wordsheet  = 'English-German'\n",
    "#wordsheet  = 'English-Italian'\n",
    "#wordsheet  = 'Test'\n",
    "\n",
    "fname      = 'TranElicit_word_lists.xlsx'\n",
    "#wordsheet  = 'English-Spanish.Task'\n",
    "#wordsheet  = 'English-Catalan.Task'\n",
    "#wordsheet  = 'Spanish-Catalan.Task'\n",
    "wordsheet  = 'FalseFriends'\n",
    "\n",
    "#fname      = 'OCDI_word_lists.xlsx'\n",
    "#wordsheet  = 'OCDI'\n",
    "#wordsheet  = 'Test'\n",
    "\n",
    "#phonesheet = 'PhoneCoding'\n",
    "phonesheet = 'PhoneCoding.broad' # collapses phoneme features into broader categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the word list from the file\n",
    "wordlist = pd.read_excel(fname, sheet_name=wordsheet, index_col='Index')\n",
    "\n",
    "#Index - numeric index (important - if the index is repeated, the code gives an error)\n",
    "#Word1 - English word (or other reference language)\n",
    "#IPA1 - IPA transcription of English word / reference language\n",
    "#Word2 - AL word\n",
    "#IPA2 - IPA transcription of AL word\n",
    "#IPA1Len - length (phoneme count) of English/reference word\n",
    "#IPA2Len - length (phoneme count) of AL word\n",
    "\n",
    "\n",
    "# identify the phoneme count of the longer word\n",
    "wordlist['LongerLen'] = np.where(wordlist['IPA1Len'] >= wordlist['IPA2Len'], wordlist['IPA1Len'], wordlist['IPA2Len'])\n",
    "\n",
    "# read the phone coding from the file\n",
    "phncodes = pd.read_excel(fname, sheet_name=phonesheet, index_col='Phone')\n",
    "\n",
    "# Code - 3 digit code for each phoneme, corresponding to manner/place/voicing or height/backness/roundedness\n",
    "# Phone - IPA phoneme\n",
    "# Consonants have codes starting 1 or 2, vowels have codes starting 7,8,9\n",
    "# consonants [0] - voicing, [1] - place, [2] - manner\n",
    "# vowels [0] - height, [1] - backness, [2] - roundedness\n",
    "\n",
    "#print(wordlist)\n",
    "#print(phncodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coche , coach , koʧe , kəʊʧ, 0.7083333333333333\n",
      "lengua , language , leɲgwa , læŋgwɪʤ, 0.8091575091575092\n",
      "moneda , money , moneða , mʌni, 0.7055555555555555\n",
      "gat , god , gat , gɒd, 0.8111111111111111\n",
      "bol , ball , bol , bɔɔl, 0.9464285714285714\n",
      "bol , ball , bɔɫ , bɔɔl, 0.9464285714285714\n",
      "aixeta , bread , əʃɛtə , brɛd, 0.3422222222222222\n",
      "camiseta , camisole , kamiseta , kæmɪsəʊl, 0.7708333333333333\n",
      "grifo , grief , gɾifo , griif, 0.8999999999999999\n",
      "martillo , martini , martiʎo , mɑɑtiini, 0.5458333333333334\n",
      "pastel , pastel , pastel , pæstɛl, 1\n",
      "perro , pear , pero , peə, 0.6964285714285714\n",
      "puerta , port , pwerta , pɔɔt, 0.5388888888888889\n",
      "caixa , cash , kaʃə , kæʃ, 0.9464285714285714\n",
      "cama , camera , kamə , kæmərə, 0.85\n",
      "cuc , cook , kuk , kʊk, 1\n"
     ]
    }
   ],
   "source": [
    "### SIMILARITY ALGORITM USING DIFFLIB.SEQUENCEMATCHER\n",
    "# https://docs.python.org/3.5/library/difflib.html#difflib.SequenceMatcher.get_matching_blocks\n",
    "\n",
    "# Using SequenceMatcher's get_opcodes instead of python-levenshtein's editops\n",
    "    \n",
    "for wrd in wordlist.index:\n",
    "    wrd1  = wordlist.loc[wrd]['IPA1'] # IPA transcription of L1 word\n",
    "    wrd2  = wordlist.loc[wrd]['IPA2']\n",
    "    ort1  = wordlist.loc[wrd]['Word1'] # orthographic form of L1 word\n",
    "    ort2  = wordlist.loc[wrd]['Word2']  \n",
    "    length= wordlist.loc[wrd]['LongerLen'] # length of longer word, to be used to calculate standardised distance\n",
    "\n",
    "    s = difflib.SequenceMatcher(None, wrd1, wrd2) # apply SequenceMatcher on word pairs\n",
    "    # Generate standardised basic similarity score (number of identical phonemes / total phonemes in longer word)\n",
    "    similarity = s.ratio() \n",
    "    #print(wrd1+', '+wrd2+', '+str(similarity)) \n",
    "\n",
    "    simEdits = s.get_opcodes() # show edit operation: equal/replace/delete/insert\n",
    "    #print(simEdits)\n",
    "    \n",
    "    # Refine calculation: identify and add weighted score for non-identical but similar phonemes\n",
    "    nsim = 0\n",
    "    for tag, i1, i2, j1, j2 in simEdits:\n",
    "        # Step 1: weight for common onset\n",
    "        # boost similarity score if the first phoneme is the same\n",
    "        if tag is 'equal' and i1 is 0 and j1 is 0:\n",
    "            nsim += 0.5 \n",
    "        \n",
    "        # Step 2: Non-identical but very similar phonemes\n",
    "        # take a closer look at the replaced phonemes\n",
    "        if tag is 'replace': \n",
    "            # Step 2a: Identify which phonemes were replaced with which\n",
    "            # SequenceMatcher output shows phoneme chunks that were replaced in between matched element\n",
    "            phn1 = wrd1[i1:i2]\n",
    "            phn2 = wrd2[j1:j2]\n",
    "            #print(tag, phn1, phn2)\n",
    "\n",
    "            list1 = list(phn1) # convert phoneme chunk into list of individual phonemes\n",
    "            list2 = list(phn2)\n",
    "                        \n",
    "            # Step 2b: Match each phoneme in the list to its phoneme code\n",
    "                # non-loop equivalent:\n",
    "                    # phnlist1[1] = phncodes.loc[phnlist1[1]]['Code'] if phnlist1[1] is not None\n",
    "            phnlist1 = list(list1) # create duplicate list for phone codes; coding tip: phnlist1 = list1 copies index, so list1 will change when phnlist is edited\n",
    "            for i in range(len(phnlist1)):\n",
    "                if phnlist1[i] is not None:\n",
    "                    phnlist1[i] = phncodes.loc[phnlist1[i]]['Code']\n",
    "                    \n",
    "            phnlist2 = list(list2)\n",
    "            for i in range(len(phnlist2)):\n",
    "                if phnlist2[i] is not None:\n",
    "                    phnlist2[i] = phncodes.loc[phnlist2[i]]['Code']\n",
    "            \n",
    "            #print(list1, list2)\n",
    "            #print(phnlist1, phnlist2)\n",
    "\n",
    "            # Does the compared phoneme in the L2 exist in the English phonological inventory?\n",
    "            IsEnglist2 = list(list2)\n",
    "            for i in range(len(IsEnglist2)):\n",
    "                if IsEnglist2[i] is not None:\n",
    "                    IsEnglist2[i] = phncodes.loc[IsEnglist2[i]]['EnglishIPA']\n",
    "            #print(IsEnglist2)\n",
    "\n",
    "            \n",
    "            # Step 2c: Identify common codes across lists (i.e. phonemes that are functionally identical, like [r] and [ɹ])\n",
    "            common = ([x for x in phnlist1 if x in phnlist2]) \n",
    "            #print(common)\n",
    "            codesim = len(common) # number of functionally-identical phonemes\n",
    "            #print(codesim)\n",
    "            nsim += codesim # add score of 1 for each identical phoneme\n",
    "\n",
    "            # Step 2d: boost similarity score if the first phoneme is functionally identical\n",
    "            if i1 is 0 and j1 is 0:\n",
    "                code1 = phnlist1[0]\n",
    "                code2 = phnlist2[0]\n",
    "                if code1 == code2:\n",
    "                    nsim += 0.5\n",
    "     \n",
    "            \n",
    "            # Step 2e: Compare non-identical phonemes\n",
    "            # 1. First remove identical phonemes matched above to avoid inflating score\n",
    "                # non-loop equivalent\n",
    "                    # phnlist1x[0] = None if phnlist1x[0] in common else phnlist1x[0]\n",
    "            phnlist1x = list(phnlist1)\n",
    "            phnlist1x[0] = None if phnlist1x[0] in common else phnlist1x[0]\n",
    "            for i in range(len(phnlist1x)):\n",
    "                if phnlist1x[i] in common:\n",
    "                    phnlist1x[i] = None\n",
    "                else:\n",
    "                    phnlist1x[i] = phnlist1x[i]\n",
    "\n",
    "            phnlist2x = list(phnlist2)\n",
    "            for i in range(len(phnlist2x)):\n",
    "                if phnlist2x[i] in common:\n",
    "                    phnlist2x[i] = None\n",
    "                else:\n",
    "                    phnlist2x[i] = phnlist2x[i]\n",
    "\n",
    "            #print(phnlist1x, phnlist2x)     \n",
    "\n",
    "            # 2. Then convert feature code to a list of digits for detailed comparison\n",
    "            # Output - List of lists\n",
    "                # https://stackoverflow.com/questions/12293208/how-to-create-a-list-of-lists\n",
    "                # Non loop equivalent\n",
    "                    # codelist1a  = [int(x) for x in str(phnlist1x[0])] if phnlist1x[0] is not None else None\n",
    "            lst1 = []\n",
    "            for i in range(len(phnlist1x)):\n",
    "                if phnlist1x[i] is not None:\n",
    "                    line  = [int(x) for x in str(phnlist1x[i])]\n",
    "                    lst1.append(line)\n",
    "                else:\n",
    "                    lst1.append(None)\n",
    "            \n",
    "            lst2 = []\n",
    "            for i in range(len(phnlist2x)):\n",
    "                if phnlist2x[i] is not None:\n",
    "                    line  = [int(x) for x in str(phnlist2x[i])]\n",
    "                    lst2.append(line)\n",
    "                else:\n",
    "                    lst2.append(None)\n",
    "            #print(lst1)\n",
    "            #print(lst2)\n",
    "            \n",
    "            codesim1 = 0\n",
    "           \n",
    "            # 3. Then compare first digit in English code to first digit in Spanish code, the second to the second, third to the third\n",
    "            # identify length of shorter list, to specify number of phonemes to compare across words\n",
    "            if len(lst1) <= len(lst2):\n",
    "                strlen = len(lst1)\n",
    "            elif len(lst1) >= len(lst2):\n",
    "                strlen = len(lst2)\n",
    "\n",
    "            # outer for-loop\n",
    "                # runs through the list of phoneme codes \"lst1\"\n",
    "            # inner for-loop\n",
    "                # uses the index to work up from the first to the last number in the code (in this case 3 numbers, with index being 0, 1, 2)\n",
    "            for i in range(strlen):\n",
    "                if lst1[i] is not None and lst2[i] is not None:\n",
    "                    # For vowels (777-999)\n",
    "                    # [0] - height, [1] - backness, [2] - roundedness\n",
    "                    if lst1[i][0] >= 7 and lst2[i][0] >= 7: # if it's a vowel replaceement\n",
    "                    # Weight option 1: Each feature change is weighted equal, and add score as long as there is at least one common feature\n",
    "                         for dgt, idgt in zip(lst1[i], range(len(lst1[i]))):\n",
    "                            if dgt == lst2[i][idgt]:\n",
    "                                codesim1 += 1/3 \n",
    "                        # If compared digits (feature) are the same, add 1/3 to the similarity score\n",
    "\n",
    "                    # For consonants (144-244)\n",
    "                    # [0] - voicing, [1] - place, [2] - manner\n",
    "                    if lst1[i][0] <= 6 and lst2[i][0] <= 6: # consonant replacement\n",
    "                    # Weight option 2: Different feature changes weighted differently\n",
    "                    # Only accept close feature changes\n",
    "                        if lst1[i][1] == lst2[i][1] and lst1[i][2] == lst2[i][2]: # voicing change\n",
    "                            codesim1 += 0.6 # allows [k] to [g]\n",
    "                        elif lst1[i][0] == lst2[i][0] and lst1[i][2] == lst2[i][2]: # place change\n",
    "                            if abs(int(lst1[i][1]) - int(lst2[i][1])) == 1: \n",
    "                                codesim1 += 0.4 # allows [n] to [ŋ]\n",
    "                        elif lst1[i][0] == lst2[i][0] and lst1[i][1] == lst2[i][1]: # manner change\n",
    "                            if abs(int(lst1[i][0]) - int(lst2[i][0])) == 1: \n",
    "                                codesim1 += 0.2 # allows [b] to [β]\n",
    "                            \n",
    "                            \n",
    "            # Possible other ways to manipulate weights:\n",
    "                # Distance of feature change (i.e. front vs mid vowel is more similar than front vs back)\n",
    "                # A consonant match adds less score than a vowel match\n",
    "            #print(codesim1)\n",
    "            nsim += codesim1\n",
    "\n",
    "    #print(nsim)\n",
    "    # Step 3: calculate standardised version of score from Step 2 to be added to initial similarity score\n",
    "    replace_ratio = nsim/length        \n",
    "    #print(replace_ratio)\n",
    "    \n",
    "    # Step 4: add the basic score and refined score together\n",
    "    similarity_phoneme = similarity + replace_ratio\n",
    "    # because of the onset phoneme boost, final score can go above 1. \n",
    "    # Round back to max value of 1 if that happens\n",
    "    similarity_phoneme = min(1, similarity_phoneme) #...why is the function to set maximum value min()\n",
    "    #print(similarity_phoneme)\n",
    "    \n",
    "    print(ort1+' , '+ort2+' , '+wrd1+' , '+wrd2+', '+str(similarity_phoneme))\n",
    "   \n",
    "    \n",
    "    #print()\n",
    "    \n",
    "# POINTS TO BE IMPROVED\n",
    "# - Currently short words are more strongly affected by the score multiplier, which doesn't match up to real life\n",
    "#   In some cases, a long word with half overlapping phonemes is more perceptually recognisable as a cognate \n",
    "#   than a 3 phoneme word with 2 overlapping phonemes, because of cohort effects (the long word has less cohorts to select from)\n",
    "\n",
    "# - recode long vowels and diphtongs as a single unit, instead of two units as it is now\n",
    "#   particularly in the case of long vowels, probably not so perceptually different from the short equivalent\n",
    "\n",
    "# - certain types of phoneme changes are likely more salient than others\n",
    "#   and this goes beyond simple differences between manner/place/voicing\n",
    "#   More likely it is language-dependent: If a language does not have a minimal pair between a particular pair of phonemes,\n",
    "#   the salience of that change would likely be perceptually negligible to the speaker\n",
    "#   Example: Japanese doesn't differentiate between /r/ and /l/\n",
    "#   Example2: English typically pronounce R as approximant [ɹ]\n",
    "#   so are less likely to recognise difference between approximant [ɹ], tap [ɾ], trill [r]\n",
    "#   Frequency of the minimal pair also likely makes a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
