
```{r}
#| label: setup
library(targets)
library(dplyr)
library(tidyr)
library(ggplot2)
library(patchwork)
library(gt)
library(gtExtras)
library(brms)
library(tidybayes)
library(ggExtra)
library(tinytable)
library(stringdist)
set.seed(1234)

# import objects
tar_config_set(
  store = here::here("_targets"),
  script = here::here("_targets.R")
)
tar_load_globals()
tar_load(participants)
tar_load(exp_participants)
tar_load(exp_responses)
tar_load(quest_responses)
tar_load(quest_participants)
tar_load(stimuli)
tar_load(epreds)
tar_load(dataset_1)
tar_load(dataset_2)
tar_load(dataset_3)
tar_load(exp_1_m0)
tar_load(exp_2_m0)
tar_load(exp_3_m1)
tar_load(exp_12_m0)


theme_set(
  theme_ggdist() +
    theme(
      panel.grid.major.y = element_line(
        colour = "grey",
        linetype = "dotted"
      )
    )
)

```

## Appendix 1: Model diagnostics

One way to diagnose the behaviour of Hamiltonian Monte Carlot (HMC, the algorithm used by Stan to explore the posterior distribution of a model) is to check whether the MCMC chains have converged. @fig-appendix-diagnostics shows the values sampled by the MCMC chains of each of the fixed coefficients of each model reported in the manuscript. Evidence of chain convergence is provided by the same region of values being sampled across the final interations of the chain, as it is the case for the three models depicted.


```{r}
#| label: fig-appendix-diagnostics
#| fig-cap: "Traceplot of MCMC posterior samples of the fixed regression coefficients of the models in Experiments 1, 2, and 3."
#| fig-width: 9
#| fig-height: 9
var_labels <- c(
  "b_Intercept" = "Intercept",
  "b_freq_zipf_2_std" = "Frequency",
  "b_lv_std" = "Cognateness",
  "b_neigh_n_h_std" = "CLPN",
  "b_neigh_n_h_std:lv_std" = "Cognateness × CLPN",
  "b_group1" = "cat-ENG vs. spa-ENG"
)

list(exp_1_m0, exp_2_m0, exp_3_m1) |>
  set_names(paste0("Experiment ", 1:3)) |>
  map_dfr(gather_draws, `b_.*`, regex = TRUE, .id = "exp") |>
  dplyr::filter(.variable != "b_Intercept") |>
  mutate(
    .value = .value / 4,
    .variable = factor(
      .variable,
      levels = names(var_labels),
      labels = var_labels
    )
  ) |>
  ggplot(aes(.iteration, .value, colour = factor(.chain))) +
  facet_grid(.variable ~ exp, scales = "free") +
  geom_line() +
  labs(
    x = "Iteration",
    y = "Value",
    colour = "Chain",
    fill = "Chain",
    linetype = "Chain"
  ) +
  scale_colour_brewer(palette = "Reds") +
  theme(
    legend.position = "top",
    legend.box = "horizontal",
    panel.border = element_rect(
      fill = NA,
      colour = "grey"
    ),
    legend.justification = c(1, 0),
    axis.title.x = element_blank(),
    axis.title.y = element_blank()
  )
```



## Appendix 2: Pooled analyses of Experiments 1 and 3

Across Experiments 1 and 3, we found strong evidence that participants efficiently exploited phonological similarity to provide accurate translations for words in an unfamiliar language, provided that few phonological neighbours of higher lexical frequency were present. @fig-coefs summarizes the posterior distribution of the regression coefficients of the models in Experiments 1 to 3.

```{r}
#| label: fig-coefs
#| fig-cap: "Posterior distribution of fixed regression coefficients of the models in Experiments 1, 2, and 3."
#| fig-width: 9
#| fig-height: 5
var_labels <- c(
  "b_Intercept" = "Intercept",
  "b_freq_zipf_2_std" = "Frequency",
  "b_lv_std" = "Similarity",
  "b_neigh_n_h_std" = "CLPN",
  "b_neigh_n_h_std:lv_std" = "Similarity × CLPN",
  "b_group1" = "cat-ENG vs. spa-ENG"
)

list(exp_1_m0, exp_2_m0, exp_3_m1) |>
  set_names(paste0("Experiment ", 1:3)) |>
  map_dfr(gather_draws, `b_.*`, regex = TRUE, .id = "exp") |>
  dplyr::filter(.variable != "b_Intercept") |>
  mutate(
    .value = .value / 4,
    .variable = factor(
      .variable,
      levels = names(var_labels),
      labels = var_labels
    )
  ) |>
  ggplot(aes(.value, reorder(exp, desc(exp)))) +
  facet_wrap(~.variable, scales = "free_x") +
  annotate(
    geom = "rect",
    xmin = -0.1 / 4,
    xmax = 0.1 / 4,
    ymin = -Inf,
    ymax = Inf,
    fill = "grey",
    alpha = 3 / 4,
    colour = NA
  ) +
  geom_vline(
    xintercept = 0,
    colour = "grey",
    linewidth = 3 / 4
  ) +
  stat_slab(
    aes(fill = after_stat(level)),
    point_interval = mode_hdi,
    .width = c(0.95, 0.89, 0.67, 1),
    outline_bars = TRUE,
    colour = "white",
    linewidth = 0.1,
    breaks = 20,
    normalize = "panels"
  ) +
  stat_spike(
    at = "median",
    size = 1,
    aes(linetype = "Median"),
    normalize = "panels"
  ) +
  labs(
    x = "Estimate",
    y = "Experiment",
    colour = "CrI",
    fill = "CrI",
    linetype = ""
  ) +
  scale_fill_brewer(palette = "Reds") +
  theme(
    legend.position = c(1, 0),
    legend.box = "horizontal",
    legend.justification = c(1, 0),
    axis.title.x = element_blank(),
    axis.title.y = element_blank()
  )
```

